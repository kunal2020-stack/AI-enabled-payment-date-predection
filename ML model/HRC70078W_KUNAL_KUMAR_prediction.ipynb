{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wcq6dWzy1ZR0",
   "metadata": {
    "id": "wcq6dWzy1ZR0"
   },
   "source": [
    "# Payment Date Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778654e",
   "metadata": {
    "id": "2778654e"
   },
   "source": [
    "\n",
    "### Importing related Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304c9e38",
   "metadata": {
    "id": "304c9e38"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy import stats\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724f5ee",
   "metadata": {
    "id": "8724f5ee"
   },
   "source": [
    "### Store the dataset into the Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "UV1MCBzVO6bh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UV1MCBzVO6bh",
    "outputId": "e45ed296-0ffc-41e6-e12c-7dbeb655be9b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "PXG_iRx9PElC",
   "metadata": {
    "id": "PXG_iRx9PElC"
   },
   "outputs": [],
   "source": [
    "mydata=pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e37f05",
   "metadata": {
    "id": "42e37f05"
   },
   "source": [
    "### Check the shape of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27cc0907",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27cc0907",
    "outputId": "291a2493-9e62-4dfb-acc3-bd3a76917033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 19)\n"
     ]
    }
   ],
   "source": [
    "print(mydata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c955d",
   "metadata": {
    "id": "b68c955d"
   },
   "source": [
    "### Check the Detail information of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e092ec9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e092ec9e",
    "outputId": "04a34491-f59e-449e-cd0e-b082e221bb92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   business_code           50000 non-null  object \n",
      " 1   cust_number             50000 non-null  object \n",
      " 2   name_customer           50000 non-null  object \n",
      " 3   clear_date              45825 non-null  object \n",
      " 4   buisness_year           50000 non-null  int64  \n",
      " 5   doc_id                  50000 non-null  int64  \n",
      " 6   posting_date            50000 non-null  object \n",
      " 7   document_create_date    50000 non-null  int64  \n",
      " 8   document_create_date.1  50000 non-null  int64  \n",
      " 9   due_in_date             50000 non-null  int64  \n",
      " 10  invoice_currency        50000 non-null  object \n",
      " 11  document type           50000 non-null  object \n",
      " 12  posting_id              50000 non-null  int64  \n",
      " 13  area_business           0 non-null      float64\n",
      " 14  total_open_amount       50000 non-null  float64\n",
      " 15  baseline_create_date    50000 non-null  int64  \n",
      " 16  cust_payment_terms      50000 non-null  object \n",
      " 17  invoice_id              49990 non-null  float64\n",
      " 18  isOpen                  50000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(8)\n",
      "memory usage: 7.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mydata.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f2d0e",
   "metadata": {
    "id": "112f2d0e"
   },
   "source": [
    "### Display All the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1416e2fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1416e2fd",
    "outputId": "644c9250-65b9-4af2-b518-a0bd196569e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_code', 'cust_number', 'name_customer', 'clear_date',\n",
      "       'buisness_year', 'doc_id', 'posting_date', 'document_create_date',\n",
      "       'document_create_date.1', 'due_in_date', 'invoice_currency',\n",
      "       'document type', 'posting_id', 'area_business', 'total_open_amount',\n",
      "       'baseline_create_date', 'cust_payment_terms', 'invoice_id', 'isOpen'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(mydata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465ed7a",
   "metadata": {
    "id": "d465ed7a"
   },
   "source": [
    "### Describe the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f65e1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "25f65e1b",
    "outputId": "683c6513-e2de-4a47-f8ae-793d886f1079"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>document_create_date</th>\n",
       "      <th>document_create_date.1</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>area_business</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>isOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>4.999000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019.204100</td>\n",
       "      <td>2.011601e+09</td>\n",
       "      <td>2.019250e+07</td>\n",
       "      <td>2.019253e+07</td>\n",
       "      <td>2.019270e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.233803e+04</td>\n",
       "      <td>2.019253e+07</td>\n",
       "      <td>2.010103e+09</td>\n",
       "      <td>0.083500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.403046</td>\n",
       "      <td>2.944254e+08</td>\n",
       "      <td>3.915166e+03</td>\n",
       "      <td>3.903101e+03</td>\n",
       "      <td>3.913433e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.018459e+04</td>\n",
       "      <td>3.902016e+03</td>\n",
       "      <td>2.747431e+08</td>\n",
       "      <td>0.276639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.928502e+09</td>\n",
       "      <td>2.018123e+07</td>\n",
       "      <td>2.018111e+07</td>\n",
       "      <td>2.018112e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500000e-01</td>\n",
       "      <td>2.018111e+07</td>\n",
       "      <td>1.928502e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.929236e+09</td>\n",
       "      <td>2.019042e+07</td>\n",
       "      <td>2.019042e+07</td>\n",
       "      <td>2.019051e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.874500e+03</td>\n",
       "      <td>2.019042e+07</td>\n",
       "      <td>1.929236e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.929807e+09</td>\n",
       "      <td>2.019081e+07</td>\n",
       "      <td>2.019081e+07</td>\n",
       "      <td>2.019082e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.742728e+04</td>\n",
       "      <td>2.019081e+07</td>\n",
       "      <td>1.929807e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.930401e+09</td>\n",
       "      <td>2.019112e+07</td>\n",
       "      <td>2.019113e+07</td>\n",
       "      <td>2.019121e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.679099e+04</td>\n",
       "      <td>2.019113e+07</td>\n",
       "      <td>1.930401e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.500000e+09</td>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>2.020071e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.501474e+06</td>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>2.960634e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buisness_year        doc_id  document_create_date  \\\n",
       "count   50000.000000  5.000000e+04          5.000000e+04   \n",
       "mean     2019.204100  2.011601e+09          2.019250e+07   \n",
       "std         0.403046  2.944254e+08          3.915166e+03   \n",
       "min      2019.000000  1.928502e+09          2.018123e+07   \n",
       "25%      2019.000000  1.929236e+09          2.019042e+07   \n",
       "50%      2019.000000  1.929807e+09          2.019081e+07   \n",
       "75%      2019.000000  1.930401e+09          2.019112e+07   \n",
       "max      2020.000000  9.500000e+09          2.020052e+07   \n",
       "\n",
       "       document_create_date.1   due_in_date  posting_id  area_business  \\\n",
       "count            5.000000e+04  5.000000e+04     50000.0            0.0   \n",
       "mean             2.019253e+07  2.019270e+07         1.0            NaN   \n",
       "std              3.903101e+03  3.913433e+03         0.0            NaN   \n",
       "min              2.018111e+07  2.018112e+07         1.0            NaN   \n",
       "25%              2.019042e+07  2.019051e+07         1.0            NaN   \n",
       "50%              2.019081e+07  2.019082e+07         1.0            NaN   \n",
       "75%              2.019113e+07  2.019121e+07         1.0            NaN   \n",
       "max              2.020052e+07  2.020071e+07         1.0            NaN   \n",
       "\n",
       "       total_open_amount  baseline_create_date    invoice_id        isOpen  \n",
       "count       5.000000e+04          5.000000e+04  4.999000e+04  50000.000000  \n",
       "mean        3.233803e+04          2.019253e+07  2.010103e+09      0.083500  \n",
       "std         4.018459e+04          3.902016e+03  2.747431e+08      0.276639  \n",
       "min         6.500000e-01          2.018111e+07  1.928502e+09      0.000000  \n",
       "25%         4.874500e+03          2.019042e+07  1.929236e+09      0.000000  \n",
       "50%         1.742728e+04          2.019081e+07  1.929807e+09      0.000000  \n",
       "75%         4.679099e+04          2.019113e+07  1.930401e+09      0.000000  \n",
       "max         1.501474e+06          2.020052e+07  2.960634e+09      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c8d02",
   "metadata": {
    "id": "0f2c8d02"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Show top 5 records from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f876212",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "8f876212",
    "outputId": "d5869243-3da3-422a-935c-442e061b8cb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_code</th>\n",
       "      <th>cust_number</th>\n",
       "      <th>name_customer</th>\n",
       "      <th>clear_date</th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>document_create_date</th>\n",
       "      <th>document_create_date.1</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>invoice_currency</th>\n",
       "      <th>document type</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>area_business</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>cust_payment_terms</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>isOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U001</td>\n",
       "      <td>200726979</td>\n",
       "      <td>BJ'S  in</td>\n",
       "      <td>13-01-2020 00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>1930330859</td>\n",
       "      <td>29-12-2019</td>\n",
       "      <td>20191228</td>\n",
       "      <td>20191229</td>\n",
       "      <td>20200113</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.16</td>\n",
       "      <td>20191229</td>\n",
       "      <td>NAA8</td>\n",
       "      <td>1.930331e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U001</td>\n",
       "      <td>200726979</td>\n",
       "      <td>BJ'S  systems</td>\n",
       "      <td>29-01-2020 00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>1930397118</td>\n",
       "      <td>14-01-2020</td>\n",
       "      <td>20200114</td>\n",
       "      <td>20200114</td>\n",
       "      <td>20200129</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>543.13</td>\n",
       "      <td>20200114</td>\n",
       "      <td>NAA8</td>\n",
       "      <td>1.930397e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U001</td>\n",
       "      <td>200434439</td>\n",
       "      <td>BAUGH SU co</td>\n",
       "      <td>31-12-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1930188160</td>\n",
       "      <td>22-11-2019</td>\n",
       "      <td>20191123</td>\n",
       "      <td>20191122</td>\n",
       "      <td>20191224</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67765.04</td>\n",
       "      <td>20191122</td>\n",
       "      <td>NA32</td>\n",
       "      <td>1.930188e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR foundation</td>\n",
       "      <td>25-06-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929472295</td>\n",
       "      <td>13-06-2019</td>\n",
       "      <td>20190611</td>\n",
       "      <td>20190613</td>\n",
       "      <td>20190628</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729.60</td>\n",
       "      <td>20190613</td>\n",
       "      <td>NAH4</td>\n",
       "      <td>1.929472e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR associates</td>\n",
       "      <td>14-05-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929243669</td>\n",
       "      <td>03-05-2019</td>\n",
       "      <td>20190502</td>\n",
       "      <td>20190503</td>\n",
       "      <td>20190518</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35911.74</td>\n",
       "      <td>20190503</td>\n",
       "      <td>NAH4</td>\n",
       "      <td>1.929244e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business_code cust_number       name_customer        clear_date  \\\n",
       "0          U001   200726979            BJ'S  in  13-01-2020 00:00   \n",
       "1          U001   200726979       BJ'S  systems  29-01-2020 00:00   \n",
       "2          U001   200434439         BAUGH SU co  31-12-2019 00:00   \n",
       "3          U001   200769623  WAL-MAR foundation  25-06-2019 00:00   \n",
       "4          U001   200769623  WAL-MAR associates  14-05-2019 00:00   \n",
       "\n",
       "   buisness_year      doc_id posting_date  document_create_date  \\\n",
       "0           2020  1930330859   29-12-2019              20191228   \n",
       "1           2020  1930397118   14-01-2020              20200114   \n",
       "2           2019  1930188160   22-11-2019              20191123   \n",
       "3           2019  1929472295   13-06-2019              20190611   \n",
       "4           2019  1929243669   03-05-2019              20190502   \n",
       "\n",
       "   document_create_date.1  due_in_date invoice_currency document type  \\\n",
       "0                20191229     20200113              USD            RV   \n",
       "1                20200114     20200129              USD            RV   \n",
       "2                20191122     20191224              USD            RV   \n",
       "3                20190613     20190628              USD            RV   \n",
       "4                20190503     20190518              USD            RV   \n",
       "\n",
       "   posting_id  area_business  total_open_amount  baseline_create_date  \\\n",
       "0           1            NaN              59.16              20191229   \n",
       "1           1            NaN             543.13              20200114   \n",
       "2           1            NaN           67765.04              20191122   \n",
       "3           1            NaN             729.60              20190613   \n",
       "4           1            NaN           35911.74              20190503   \n",
       "\n",
       "  cust_payment_terms    invoice_id  isOpen  \n",
       "0               NAA8  1.930331e+09       0  \n",
       "1               NAA8  1.930397e+09       0  \n",
       "2               NA32  1.930188e+09       0  \n",
       "3               NAH4  1.929472e+09       0  \n",
       "4               NAH4  1.929244e+09       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b044e4",
   "metadata": {
    "id": "92b044e4"
   },
   "source": [
    "### Display the Null values percentage against every columns (compare to the total number of records)\n",
    "\n",
    "- Output expected : area_business - 100% null, clear_data = 20% null, invoice_id = 0.12% null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c7b13d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24c7b13d",
    "outputId": "ab4e4d59-9f45-4e55-ccd0-e9e8f81c86ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_code               0.00\n",
       "cust_number                 0.00\n",
       "name_customer               0.00\n",
       "clear_date                  8.35\n",
       "buisness_year               0.00\n",
       "doc_id                      0.00\n",
       "posting_date                0.00\n",
       "document_create_date        0.00\n",
       "document_create_date.1      0.00\n",
       "due_in_date                 0.00\n",
       "invoice_currency            0.00\n",
       "document type               0.00\n",
       "posting_id                  0.00\n",
       "area_business             100.00\n",
       "total_open_amount           0.00\n",
       "baseline_create_date        0.00\n",
       "cust_payment_terms          0.00\n",
       "invoice_id                  0.02\n",
       "isOpen                      0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_v_p = mydata.isnull().sum() * 100 / len(mydata)\n",
    "null_v_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46a98b",
   "metadata": {
    "id": "2c46a98b"
   },
   "source": [
    "### Display Invoice_id and Doc_Id\n",
    "\n",
    "- Note - Many of the would have same invoice_id and doc_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038f24bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "038f24bb",
    "outputId": "402b0052-1a4f-4fe7-c9e1-6f9dcf36eaae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49990\n",
      "         invoice_id      doc_id\n",
      "0      1.930331e+09  1930330859\n",
      "1      1.930397e+09  1930397118\n",
      "2      1.930188e+09  1930188160\n",
      "3      1.929472e+09  1929472295\n",
      "4      1.929244e+09  1929243669\n",
      "...             ...         ...\n",
      "49995  1.930748e+09  1930748404\n",
      "49996  1.930854e+09  1930853778\n",
      "49997  1.930733e+09  1930733320\n",
      "49998  1.930764e+09  1930764307\n",
      "49999  1.930599e+09  1930599295\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "comp = np.where(mydata[\"invoice_id\"] == mydata[\"doc_id\"], True, False)\n",
    "flag=0\n",
    "for data in comp:\n",
    "    if data==True:\n",
    "      flag+=1\n",
    "print(flag) \n",
    "\n",
    "print(mydata[['invoice_id','doc_id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfe10a",
   "metadata": {
    "id": "18cfe10a"
   },
   "source": [
    "#### Write a code to check - 'baseline_create_date',\"document_create_date\",'document_create_date.1' - these columns are almost same.\n",
    "\n",
    "- Please note, if they are same, we need to drop them later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5b40ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf5b40ff",
    "outputId": "f3415c2c-17e2-4f34-cc47-65f110df67ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44536\n",
      "       document_create_date.1  baseline_create_date\n",
      "0                    20191229              20191229\n",
      "1                    20200114              20200114\n",
      "2                    20191122              20191122\n",
      "3                    20190613              20190613\n",
      "4                    20190503              20190503\n",
      "...                       ...                   ...\n",
      "49995                20200406              20200406\n",
      "49996                20200504              20200504\n",
      "49997                20200402              20200402\n",
      "49998                20200409              20200409\n",
      "49999                20200304              20200301\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "comp = np.where(mydata['document_create_date.1'] == mydata['baseline_create_date'], True, False)\n",
    "flag=0\n",
    "for data in comp:\n",
    "    if data==True:\n",
    "      flag+=1\n",
    "print(flag) \n",
    "print(mydata[['document_create_date.1','baseline_create_date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33110576",
   "metadata": {
    "id": "33110576"
   },
   "source": [
    "#### Please check, Column 'posting_id' is constant columns or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecce2664",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecce2664",
    "outputId": "7aa08315-9718-44f0-990c-e445c19e6a0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "if(mydata['posting_id'].nunique()==1):#mydata['posting_id].nunique will return 1 if all the value are same i.e constant\n",
    "        print('true')#returs true if all values are same\n",
    "else:\n",
    "  print(\"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb8daf",
   "metadata": {
    "id": "e5fb8daf"
   },
   "source": [
    "#### Please check 'isOpen' is a constant column and relevant column for this project or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db9956b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8db9956b",
    "outputId": "d6158052-f06c-4509-a4a6-29f2b1a3651c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45825\n",
       "1     4175\n",
       "Name: isOpen, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata['isOpen'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "OzGBHG6vGSKu",
   "metadata": {
    "id": "OzGBHG6vGSKu"
   },
   "outputs": [],
   "source": [
    "#Though column is not constant but it is more like a Quasi constant\n",
    "#Also it will not help in predicting our result so it is better to drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a11a62",
   "metadata": {
    "id": "45a11a62"
   },
   "source": [
    "### Write the code to drop all the following columns from the dataframe\n",
    "\n",
    "- 'area_business'\n",
    "- \"posting_id\"\n",
    "- \"invoice_id\"\n",
    "- \"document_create_date\"\n",
    "- \"isOpen\"\n",
    "- 'document type' \n",
    "- 'document_create_date.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "270d85d1",
   "metadata": {
    "id": "270d85d1"
   },
   "outputs": [],
   "source": [
    "mydata.drop(columns=['area_business','posting_id','invoice_id','document_create_date','isOpen','document type','document_create_date.1'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K5LHAM2XVGnk",
   "metadata": {
    "id": "K5LHAM2XVGnk"
   },
   "source": [
    "### Please check from the dataframe whether all the columns are removed or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef3f7d2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "ef3f7d2b",
    "outputId": "eaaf9ec6-3c98-43fa-d898-c398188d5fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_code</th>\n",
       "      <th>cust_number</th>\n",
       "      <th>name_customer</th>\n",
       "      <th>clear_date</th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>invoice_currency</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>cust_payment_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U001</td>\n",
       "      <td>200726979</td>\n",
       "      <td>BJ'S  in</td>\n",
       "      <td>13-01-2020 00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>1930330859</td>\n",
       "      <td>29-12-2019</td>\n",
       "      <td>20200113</td>\n",
       "      <td>USD</td>\n",
       "      <td>59.16</td>\n",
       "      <td>20191229</td>\n",
       "      <td>NAA8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U001</td>\n",
       "      <td>200726979</td>\n",
       "      <td>BJ'S  systems</td>\n",
       "      <td>29-01-2020 00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>1930397118</td>\n",
       "      <td>14-01-2020</td>\n",
       "      <td>20200129</td>\n",
       "      <td>USD</td>\n",
       "      <td>543.13</td>\n",
       "      <td>20200114</td>\n",
       "      <td>NAA8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U001</td>\n",
       "      <td>200434439</td>\n",
       "      <td>BAUGH SU co</td>\n",
       "      <td>31-12-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1930188160</td>\n",
       "      <td>22-11-2019</td>\n",
       "      <td>20191224</td>\n",
       "      <td>USD</td>\n",
       "      <td>67765.04</td>\n",
       "      <td>20191122</td>\n",
       "      <td>NA32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR foundation</td>\n",
       "      <td>25-06-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929472295</td>\n",
       "      <td>13-06-2019</td>\n",
       "      <td>20190628</td>\n",
       "      <td>USD</td>\n",
       "      <td>729.60</td>\n",
       "      <td>20190613</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR associates</td>\n",
       "      <td>14-05-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929243669</td>\n",
       "      <td>03-05-2019</td>\n",
       "      <td>20190518</td>\n",
       "      <td>USD</td>\n",
       "      <td>35911.74</td>\n",
       "      <td>20190503</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business_code cust_number       name_customer        clear_date  \\\n",
       "0          U001   200726979            BJ'S  in  13-01-2020 00:00   \n",
       "1          U001   200726979       BJ'S  systems  29-01-2020 00:00   \n",
       "2          U001   200434439         BAUGH SU co  31-12-2019 00:00   \n",
       "3          U001   200769623  WAL-MAR foundation  25-06-2019 00:00   \n",
       "4          U001   200769623  WAL-MAR associates  14-05-2019 00:00   \n",
       "\n",
       "   buisness_year      doc_id posting_date  due_in_date invoice_currency  \\\n",
       "0           2020  1930330859   29-12-2019     20200113              USD   \n",
       "1           2020  1930397118   14-01-2020     20200129              USD   \n",
       "2           2019  1930188160   22-11-2019     20191224              USD   \n",
       "3           2019  1929472295   13-06-2019     20190628              USD   \n",
       "4           2019  1929243669   03-05-2019     20190518              USD   \n",
       "\n",
       "   total_open_amount  baseline_create_date cust_payment_terms  \n",
       "0              59.16              20191229               NAA8  \n",
       "1             543.13              20200114               NAA8  \n",
       "2           67765.04              20191122               NA32  \n",
       "3             729.60              20190613               NAH4  \n",
       "4           35911.74              20190503               NAH4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mydata.shape)\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc052c7",
   "metadata": {
    "id": "6bc052c7"
   },
   "source": [
    "### Show all the Duplicate rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae3c7e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "1ae3c7e4",
    "outputId": "d6a62922-8876-437c-e96d-ca0ff06333f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_code</th>\n",
       "      <th>cust_number</th>\n",
       "      <th>name_customer</th>\n",
       "      <th>clear_date</th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>invoice_currency</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>cust_payment_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [business_code, cust_number, name_customer, clear_date, buisness_year, doc_id, posting_date, due_in_date, invoice_currency, total_open_amount, baseline_create_date, cust_payment_terms]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[mydata.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fab09",
   "metadata": {
    "id": "464fab09"
   },
   "source": [
    "### Display the Number of Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1ea2397",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1ea2397",
    "outputId": "e5ac3d82-ece3-40ff-ed38-686b27a844ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a6718",
   "metadata": {
    "id": "827a6718"
   },
   "source": [
    "### Drop all the Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d10151c",
   "metadata": {
    "id": "5d10151c"
   },
   "outputs": [],
   "source": [
    "mydata.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d1f9b",
   "metadata": {
    "id": "7e5d1f9b"
   },
   "source": [
    "#### Now check for all duplicate rows now\n",
    "\n",
    "- Note - It must be 0 by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9accc9fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9accc9fc",
    "outputId": "0f3d4b12-e972-48bb-d537-872060056030"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0704898",
   "metadata": {
    "id": "d0704898"
   },
   "source": [
    "### Check for the number of Rows and Columns in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "582748a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "582748a8",
    "outputId": "1f9bd2b3-c62a-4e56-f0f4-1974bb8650cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4o9c5UodWRtl",
   "metadata": {
    "id": "4o9c5UodWRtl"
   },
   "source": [
    "### Find out the total count of null values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0612cb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0612cb5",
    "outputId": "14574958-31b4-41a6-91b6-0c3078627cb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_code              0\n",
       "cust_number                0\n",
       "name_customer              0\n",
       "clear_date              4175\n",
       "buisness_year              0\n",
       "doc_id                     0\n",
       "posting_date               0\n",
       "due_in_date                0\n",
       "invoice_currency           0\n",
       "total_open_amount          0\n",
       "baseline_create_date       0\n",
       "cust_payment_terms         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdb98b",
   "metadata": {
    "id": "7abdb98b"
   },
   "source": [
    "#Data type Conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPfSUSp-WpPj",
   "metadata": {
    "id": "LPfSUSp-WpPj"
   },
   "source": [
    "### Please check the data type of each column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "689c8592",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "689c8592",
    "outputId": "d9b9320a-f21a-416b-9b65-43a00977310d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_code            object\n",
       "cust_number              object\n",
       "name_customer            object\n",
       "clear_date               object\n",
       "buisness_year             int64\n",
       "doc_id                    int64\n",
       "posting_date             object\n",
       "due_in_date               int64\n",
       "invoice_currency         object\n",
       "total_open_amount       float64\n",
       "baseline_create_date      int64\n",
       "cust_payment_terms       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nsem0_3XzOt",
   "metadata": {
    "id": "0nsem0_3XzOt"
   },
   "source": [
    "### Check the datatype format of below columns\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "-yyODyW3X6pL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yyODyW3X6pL",
    "outputId": "658ddf19-f684-4d0f-e525-43aebad66306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clear_date              object\n",
       "posting_date            object\n",
       "due_in_date              int64\n",
       "baseline_create_date     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.dtypes[['clear_date','posting_date','due_in_date','baseline_create_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf9478",
   "metadata": {
    "id": "11cf9478"
   },
   "source": [
    "### converting date columns into date time formats\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date\n",
    "\n",
    "\n",
    "- **Note - You have to convert all these above columns into \"%Y%m%d\" format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a8c6c71",
   "metadata": {
    "id": "9a8c6c71"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data 13-01-2020 00:00 doesn't match format specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2191\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2192\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2193\u001b[0m             \u001b[1;31m# If tzaware, these values represent unix timestamps, so we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16600/923227250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clear_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clear_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'posting_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'posting_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'due_in_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'due_in_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'due_in_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'due_in_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'baseline_create_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'baseline_create_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mcache_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mutc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"utc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[0;32m    402\u001b[0m         \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2196\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2198\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2178\u001b[0m     \u001b[0morder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"F\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2180\u001b[1;33m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[0;32m   2181\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2182\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data 13-01-2020 00:00 doesn't match format specified"
     ]
    }
   ],
   "source": [
    "mydata['clear_date']=pd.to_datetime(mydata['clear_date'],format='%Y-%m-%d')\n",
    "mydata['posting_date']=pd.to_datetime(mydata['posting_date'],format='%Y-%m-%d')\n",
    "mydata['due_in_date']=mydata['due_in_date'].astype(int)\n",
    "mydata['due_in_date']=pd.to_datetime(mydata['due_in_date'],format='%Y%m%d')\n",
    "mydata['baseline_create_date']=mydata['baseline_create_date'].astype(int)\n",
    "mydata['baseline_create_date']=pd.to_datetime(mydata['baseline_create_date'],format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adq0wSIYSCS",
   "metadata": {
    "id": "7adq0wSIYSCS"
   },
   "source": [
    "### Please check the datatype of all the columns after conversion of the above 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd028c61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd028c61",
    "outputId": "2ed46846-739b-4d49-85cc-6089c9da2fa6"
   },
   "outputs": [],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9882fa",
   "metadata": {
    "id": "8c9882fa"
   },
   "source": [
    "#### the invoice_currency column contains two different categories, USD and CAD\n",
    "\n",
    "- Please do a count of each currency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72085397",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72085397",
    "outputId": "d11bccc9-c2fd-42ed-a4d1-244cfcb18171"
   },
   "outputs": [],
   "source": [
    "mydata['invoice_currency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe26ee",
   "metadata": {
    "id": "6cbe26ee"
   },
   "source": [
    "#### display the \"total_open_amount\" column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49f2ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c49f2ab",
    "outputId": "6078899f-bd68-44d5-b18b-e4f9ff54e593"
   },
   "outputs": [],
   "source": [
    "mydata['total_open_amount'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df899966",
   "metadata": {
    "id": "df899966"
   },
   "source": [
    "### Convert all CAD into USD currency of \"total_open_amount\" column\n",
    "\n",
    "- 1 CAD = 0.7 USD\n",
    "- Create a new column i.e \"converted_usd\" and store USD and convered CAD to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2f1c5",
   "metadata": {
    "id": "8eb2f1c5"
   },
   "outputs": [],
   "source": [
    "mydata['converted_usd']=np.where(mydata['invoice_currency']=='CAD',mydata['total_open_amount']*0.7,mydata['total_open_amount']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6ef1d",
   "metadata": {
    "id": "f9f6ef1d"
   },
   "source": [
    "### Display the new \"converted_usd\" column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1a178",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fc1a178",
    "outputId": "4464993f-a711-4329-ff3a-79b04ea117bb"
   },
   "outputs": [],
   "source": [
    "mydata.converted_usd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6XLXX17kayuy",
   "metadata": {
    "id": "6XLXX17kayuy"
   },
   "source": [
    "### Display year wise total number of record \n",
    "\n",
    "- Note -  use \"buisness_year\" column for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9f6ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00c9f6ee",
    "outputId": "89ca9054-3e8d-4a35-b69a-680c91a4c26a"
   },
   "outputs": [],
   "source": [
    "mydata['buisness_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c35904",
   "metadata": {
    "id": "05c35904"
   },
   "source": [
    "### Write the code to delete the following columns \n",
    "\n",
    "- 'invoice_currency'\n",
    "- 'total_open_amount', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac28aa5",
   "metadata": {
    "id": "4ac28aa5"
   },
   "outputs": [],
   "source": [
    "mydata.drop(columns=['invoice_currency','total_open_amount'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bDBJ_Kvwc086",
   "metadata": {
    "id": "bDBJ_Kvwc086"
   },
   "source": [
    "### Write a code to check the number of columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea360a8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea360a8c",
    "outputId": "15698667-2d58-405b-abc4-2f9b9f577c4d"
   },
   "outputs": [],
   "source": [
    "len(mydata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f63655",
   "metadata": {
    "id": "b8f63655"
   },
   "source": [
    "# Splitting the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f749d",
   "metadata": {
    "id": "a00f749d"
   },
   "source": [
    "### Look for all columns containing null value\n",
    "\n",
    "- Note - Output expected is only one column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c801e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "148c801e",
    "outputId": "c7072d5c-942e-437c-f821-607dd22602d0"
   },
   "outputs": [],
   "source": [
    "print(mydata.columns[mydata.isna().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094a290",
   "metadata": {
    "id": "a094a290"
   },
   "source": [
    "#### Find out the number of null values from the column that you got from the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfb113",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30bfb113",
    "outputId": "54d4508a-a043-4eaf-c6a0-deb4ecf8a25f"
   },
   "outputs": [],
   "source": [
    "mydata['clear_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d939b",
   "metadata": {
    "id": "7f6d939b"
   },
   "source": [
    "### On basis of the above column we are spliting data into dataset\n",
    "\n",
    "- First dataframe (refer that as maindata) only containing the rows, that have NO NULL data in that column ( This is going to be our train dataset ) \n",
    "- Second dataframe (refer that as nulldata) that contains the columns, that have Null data in that column ( This is going to be our test dataset ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8764c33",
   "metadata": {
    "id": "c8764c33"
   },
   "outputs": [],
   "source": [
    "maindata = mydata[mydata['clear_date'].notnull()].copy()\n",
    "nulldata=mydata[mydata['clear_date'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3P8riRBHd_r6",
   "metadata": {
    "id": "3P8riRBHd_r6"
   },
   "source": [
    "### Check the number of Rows and Columns for both the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693a464",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0693a464",
    "outputId": "0141092f-b15a-4af6-94b0-2c5da47573db"
   },
   "outputs": [],
   "source": [
    "maindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86bc74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f86bc74",
    "outputId": "e0482c76-f8d2-4359-e8b8-89417ce79708"
   },
   "outputs": [],
   "source": [
    "nulldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747165d",
   "metadata": {
    "id": "0747165d"
   },
   "source": [
    "### Display the 5 records from maindata and nulldata dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2ec36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "dec2ec36",
    "outputId": "11694470-809f-4310-e86b-9d0c2ecb28e2"
   },
   "outputs": [],
   "source": [
    "maindata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2d68a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "eee2d68a",
    "outputId": "c95279ac-4ef6-41f3-94dd-1df055eccff0"
   },
   "outputs": [],
   "source": [
    "nulldata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa6746",
   "metadata": {
    "id": "24aa6746"
   },
   "source": [
    "## Considering the **maindata**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c4aa7",
   "metadata": {
    "id": "f92c4aa7"
   },
   "source": [
    "#### Generate a new column \"Delay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to create a new column 'Delay' from two existing columns, \"clear_date\" and \"due_in_date\" \n",
    "- Formula - Delay = clear_date - due_in_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeceb9c",
   "metadata": {
    "id": "8eeceb9c"
   },
   "outputs": [],
   "source": [
    "maindata['Delay']=(maindata['clear_date']-maindata['due_in_date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482144e",
   "metadata": {
    "id": "f482144e"
   },
   "source": [
    "### Generate a new column \"avgdelay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to make a new column \"avgdelay\" by grouping \"name_customer\" column with reapect to mean of the \"Delay\" column.\n",
    "- This new column \"avg_delay\" is meant to store \"customer_name\" wise delay\n",
    "- groupby('name_customer')['Delay'].mean(numeric_only=False)\n",
    "- Display the new \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d2f8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d18d2f8d",
    "outputId": "16946758-97b7-4e0a-80de-eb0239806c17"
   },
   "outputs": [],
   "source": [
    "avgdelay=maindata.groupby(['name_customer'])['Delay'].mean(numeric_only=False)\n",
    "avgdelay.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b995e8",
   "metadata": {
    "id": "64b995e8"
   },
   "source": [
    "You need to add the \"avg_delay\" column with the maindata, mapped with \"name_customer\" column\n",
    "\n",
    " - Note - You need to use map function to map the avgdelay with respect to \"name_customer\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1f3d9",
   "metadata": {
    "id": "e1e1f3d9"
   },
   "outputs": [],
   "source": [
    "maindata['avg_delay']=maindata['name_customer'].map(avgdelay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d332525",
   "metadata": {
    "id": "1d332525"
   },
   "source": [
    "### Observe that the \"avg_delay\" column is in days format. You need to change the format into seconds\n",
    "\n",
    "- Days_format :  17 days 00:00:00\n",
    "- Format in seconds : 1641600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1041e",
   "metadata": {
    "id": "d5f1041e"
   },
   "outputs": [],
   "source": [
    "maindata['avg_delay'] = maindata['avg_delay']*86400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvgtHSsx_O-n",
   "metadata": {
    "id": "OvgtHSsx_O-n"
   },
   "source": [
    "### Display the maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca9c45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "97ca9c45",
    "outputId": "7668ebf4-aebe-4969-8f31-7e5e03d65d69"
   },
   "outputs": [],
   "source": [
    "maindata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24c7bb",
   "metadata": {
    "id": "ae24c7bb"
   },
   "source": [
    "### Since you have created the \"avg_delay\" column from \"Delay\" and \"clear_date\" column, there is no need of these two columns anymore \n",
    "\n",
    "- You are expected to drop \"Delay\" and \"clear_date\" columns from maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a61ab9",
   "metadata": {
    "id": "78a61ab9"
   },
   "outputs": [],
   "source": [
    "maindata.drop(columns=['Delay','clear_date'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae724bfc",
   "metadata": {
    "id": "ae724bfc"
   },
   "source": [
    "# Splitting of Train and the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f0264",
   "metadata": {
    "id": "cb6f0264"
   },
   "source": [
    "### You need to split the \"maindata\" columns into X and y dataframe\n",
    "\n",
    "- Note - y should have the target column i.e. \"avg_delay\" and the other column should be in X\n",
    "\n",
    "- X is going to hold the source fields and y will be going to hold the target fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab29ab",
   "metadata": {
    "id": "75ab29ab"
   },
   "outputs": [],
   "source": [
    "y = maindata['avg_delay'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412c62b",
   "metadata": {
    "id": "6412c62b"
   },
   "outputs": [],
   "source": [
    "X = maindata.drop([\"avg_delay\"], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2942bf",
   "metadata": {
    "id": "1c2942bf"
   },
   "source": [
    "#### You are expected to split both the dataframes into train and test format in 60:40 ratio \n",
    "\n",
    "- Note - The expected output should be in \"X_train\", \"X_loc_test\", \"y_train\", \"y_loc_test\" format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92160a5",
   "metadata": {
    "id": "d92160a5"
   },
   "outputs": [],
   "source": [
    "X_train ,X_loc_test, y_train, y_loc_test = train_test_split(X, y, test_size = 0.4,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p4OME62pDufR",
   "metadata": {
    "id": "p4OME62pDufR"
   },
   "source": [
    "### Please check for the number of rows and columns of all the new dataframes (all 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48328d0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48328d0a",
    "outputId": "da479f76-383c-4960-c81e-961377852875"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape ,X_loc_test.shape, y_train.shape, y_loc_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68ed71",
   "metadata": {
    "id": "4a68ed71"
   },
   "source": [
    "### Now you are expected to split the \"X_loc_test\" and \"y_loc_test\" dataset into \"Test\" and \"Validation\" (as the names given below) dataframe with 50:50 format \n",
    "\n",
    "- Note - The expected output should be in \"X_val\", \"X_test\", \"y_val\", \"y_test\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c62f2",
   "metadata": {
    "id": "b56c62f2"
   },
   "outputs": [],
   "source": [
    "X_val,X_test,y_val,y_test = train_test_split(X_loc_test,y_loc_test,test_size=0.5,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bJTSAskvERH1",
   "metadata": {
    "id": "bJTSAskvERH1"
   },
   "source": [
    "### Please check for the number of rows and columns of all the 4 dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d7564",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "845d7564",
    "outputId": "0f51fefe-c178-4551-f6da-a7c42a9fd166"
   },
   "outputs": [],
   "source": [
    "print(X_val.shape,X_test.shape,y_val.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fa872",
   "metadata": {
    "id": "110fa872"
   },
   "source": [
    "# Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8fe0f",
   "metadata": {
    "id": "ffc8fe0f"
   },
   "source": [
    "### Distribution Plot of the target variable (use the dataframe which contains the target field)\n",
    "\n",
    "- Note - You are expected to make a distribution plot for the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bf8ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "ba2bf8ed",
    "outputId": "915d4c08-23fa-4388-8a08-0833eba4f9f7"
   },
   "outputs": [],
   "source": [
    "sns.distplot(y,color='blue')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e323a3",
   "metadata": {
    "id": "d0e323a3"
   },
   "source": [
    "### You are expected to group the X_train dataset on 'name_customer' column with 'doc_id' in the x_train set\n",
    "\n",
    "### Need to store the outcome into a new dataframe \n",
    "\n",
    "- Note code given for groupby statement- X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acf0ee",
   "metadata": {
    "id": "f7acf0ee"
   },
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cA43bFffFt6i",
   "metadata": {
    "id": "cA43bFffFt6i"
   },
   "source": [
    "### You can make another distribution plot of the \"doc_id\" column from x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576bf33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "9576bf33",
    "outputId": "d0699902-a61b-4d19-9a3a-bb23360e989c"
   },
   "outputs": [],
   "source": [
    "sns.distplot(x_train['doc_id'],color='orange')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2c44f",
   "metadata": {
    "id": "fba2c44f"
   },
   "source": [
    "#### Create a Distribution plot only for business_year and a seperate distribution plot of \"business_year\" column along with the doc_id\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecec77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "4fecec77",
    "outputId": "c79641cb-6251-4f41-9091-6f82663967a0"
   },
   "outputs": [],
   "source": [
    "sns.distplot(X_train['buisness_year'],color='red')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qr1jGhfOKjnw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "qr1jGhfOKjnw",
    "outputId": "47703995-e94f-498b-bf3d-f6043b7099c5"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x = \"buisness_year\", y = \"doc_id\", data = X_train,color='Violet',kind='hex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968fbcc9",
   "metadata": {
    "id": "968fbcc9"
   },
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jbh6CyGqH3XE",
   "metadata": {
    "id": "jbh6CyGqH3XE"
   },
   "source": [
    "### Display and describe the X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcf307",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "e6bcf307",
    "outputId": "f29322a9-7b3a-4f70-9bf9-445899f7ecd3"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc819",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "08ccc819",
    "outputId": "d25e9d3f-3287-4c2f-da80-d5d208b7d326"
   },
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7ac8b",
   "metadata": {
    "id": "abd7ac8b"
   },
   "source": [
    "#### The \"business_code\" column inside X_train, is a categorical column, so you need to perform Labelencoder on that particular column\n",
    "\n",
    "- Note - call the Label Encoder from sklearn library and use the fit() function on \"business_code\" column\n",
    "- Note - Please fill in the blanks (two) to complete this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c223545",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c223545",
    "outputId": "6deec105-0ecc-47b3-90ae-9767788a99ca"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "business_coder = LabelEncoder()\n",
    "business_coder.fit(X_train['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f7d9c",
   "metadata": {
    "id": "f86f7d9c"
   },
   "source": [
    "#### You are expected to store the value into a new column i.e. \"business_code_enc\"\n",
    "\n",
    "- Note - For Training set you are expected to use fit_trainsform()\n",
    "- Note - For Test set you are expected to use the trainsform()\n",
    "- Note - For Validation set you are expected to use the trainsform()\n",
    "\n",
    "\n",
    "- Partial code is provided, please fill in the blanks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269c307",
   "metadata": {
    "id": "4269c307"
   },
   "outputs": [],
   "source": [
    "X_train['business_code_enc'] = business_coder.fit_transform(X_train['business_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a53712",
   "metadata": {
    "id": "70a53712"
   },
   "outputs": [],
   "source": [
    "X_val['business_code_enc'] = business_coder.transform(X_val['business_code'])\n",
    "X_test['business_code_enc'] = business_coder.transform(X_test['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gdNYxTkqNfmz",
   "metadata": {
    "id": "gdNYxTkqNfmz"
   },
   "source": [
    "### Display \"business_code\" and \"business_code_enc\" together from X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196a002",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1196a002",
    "outputId": "320b41e0-fcc0-46be-ccc0-bedf4984694f"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,['business_code','business_code_enc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11477224",
   "metadata": {
    "id": "11477224"
   },
   "source": [
    "#### Create a function called \"custom\" for dropping the columns 'business_code' from train, test and validation dataframe\n",
    "\n",
    "- Note - Fill in the blank to complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052868a",
   "metadata": {
    "id": "1052868a"
   },
   "outputs": [],
   "source": [
    "def custom(col ,traindf = X_train,valdf = X_val,testdf = X_test):\n",
    "    traindf.drop(col, axis =1,inplace=True)\n",
    "    valdf.drop(col,axis=1 , inplace=True)\n",
    "    testdf.drop(col,axis=1 , inplace=True)\n",
    "\n",
    "    return traindf,valdf ,testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rI--ZuMbNLne",
   "metadata": {
    "id": "rI--ZuMbNLne"
   },
   "source": [
    "### Call the function by passing the column name which needed to be dropped from train, test and validation dataframes. Return updated dataframes to be stored in X_train ,X_val, X_test  \n",
    "\n",
    "- Note = Fill in the blank to complete the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f955c",
   "metadata": {
    "id": "1a0f955c"
   },
   "outputs": [],
   "source": [
    "X_train,X_val,X_test=custom(['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5b27e",
   "metadata": {
    "id": "28b5b27e"
   },
   "source": [
    "### Manually replacing str values with numbers, Here we are trying manually replace the customer numbers with some specific values like, 'CCCA' as 1, 'CCU' as 2 and so on. Also we are converting the datatype \"cust_number\" field to int type.\n",
    "\n",
    "- We are doing it for all the three dataframes as shown below. This is fully completed code. No need to modify anything here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd129e",
   "metadata": {
    "id": "85dd129e"
   },
   "outputs": [],
   "source": [
    "X_train['cust_number'] = X_train['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_test['cust_number'] = X_test['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_val['cust_number'] = X_val['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U8vA-zmdPnJ8",
   "metadata": {
    "id": "U8vA-zmdPnJ8"
   },
   "source": [
    "#### It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]. Unknown will be added in fit and transform will take care of new item. It gives unknown class id.\n",
    "\n",
    "#### This will fit the encoder for all the unique values and introduce unknown value\n",
    "\n",
    "- Note - Keep this code as it is, we will be using this later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f48ba",
   "metadata": {
    "id": "151f48ba"
   },
   "outputs": [],
   "source": [
    "#For encoding unseen labels\n",
    "class EncoderExt(object):\n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    def fit(self, data_list):\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "        return self\n",
    "    def transform(self, data_list):\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "        return self.label_encoder.transform(new_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c64e6",
   "metadata": {
    "id": "254c64e6"
   },
   "source": [
    "### Use the user define Label Encoder function called \"EncoderExt\" for the \"name_customer\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b17eff",
   "metadata": {
    "id": "62b17eff"
   },
   "outputs": [],
   "source": [
    "label_encoder = EncoderExt()\n",
    "label_encoder.fit(X_train['name_customer'])\n",
    "X_train['name_customer_enc']=label_encoder.transform(X_train['name_customer'])\n",
    "X_val['name_customer_enc']=label_encoder.transform(X_val['name_customer'])\n",
    "X_test['name_customer_enc']=label_encoder.transform(X_test['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mK7LMoy2QZhy",
   "metadata": {
    "id": "mK7LMoy2QZhy"
   },
   "source": [
    "### As we have created the a new column \"name_customer_enc\", so now drop \"name_customer\" column from all three dataframes\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85f1c0",
   "metadata": {
    "id": "ef85f1c0"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa09d22",
   "metadata": {
    "id": "3aa09d22"
   },
   "source": [
    "### Using Label Encoder for the \"cust_payment_terms\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ab642",
   "metadata": {
    "id": "6f9ab642"
   },
   "outputs": [],
   "source": [
    "label_encoder1 = EncoderExt()\n",
    "label_encoder1.fit(X_train['cust_payment_terms'])\n",
    "X_train['cust_payment_terms_enc']=label_encoder1.transform(X_train['cust_payment_terms'])\n",
    "X_val['cust_payment_terms_enc']=label_encoder1.transform(X_val['cust_payment_terms'])\n",
    "X_test['cust_payment_terms_enc']=label_encoder1.transform(X_test['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9a7c2",
   "metadata": {
    "id": "55f9a7c2"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788f42b",
   "metadata": {
    "id": "0788f42b"
   },
   "source": [
    "## Check the datatype of all the columns of Train, Test and Validation dataframes realted to X\n",
    "\n",
    "- Note - You are expected yo use dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79a316",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc79a316",
    "outputId": "b689d2f1-bfe3-43ab-c3b9-16346ff9c84d"
   },
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33242d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b33242d8",
    "outputId": "c7804a29-88f0-4795-997a-1b8ca643fead"
   },
   "outputs": [],
   "source": [
    "X_val.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4da71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bd4da71",
    "outputId": "a0b619ad-0500-4fa1-a4a3-ca44b559dba8"
   },
   "outputs": [],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LVfvuPiWPeMB",
   "metadata": {
    "id": "LVfvuPiWPeMB"
   },
   "source": [
    "### From the above output you can notice their are multiple date columns with datetime format\n",
    "\n",
    "### In order to pass it into our model, we need to convert it into float format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d344db9",
   "metadata": {
    "id": "9d344db9"
   },
   "source": [
    "### You need to extract day, month and year from the \"posting_date\" column \n",
    "\n",
    "1.   Extract days from \"posting_date\" column and store it into a new column \"day_of_postingdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"posting_date\" column and store it into a new column \"month_of_postingdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"posting_date\" column and store it into a new column \"year_of_postingdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cdfd6",
   "metadata": {
    "id": "6e3cdfd6"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_postingdate'] = X_train['posting_date'].dt.day\n",
    "X_train['month_of_postingdate'] = X_train['posting_date'].dt.month\n",
    "X_train['year_of_postingdate'] = X_train['posting_date'].dt.year\n",
    "\n",
    "X_val['day_of_postingdate'] = X_val['posting_date'].dt.day\n",
    "X_val['month_of_postingdate'] = X_val['posting_date'].dt.month\n",
    "X_val['year_of_postingdate'] = X_val['posting_date'].dt.year\n",
    "\n",
    "\n",
    "X_test['day_of_postingdate'] = X_test['posting_date'].dt.day\n",
    "X_test['month_of_postingdate'] = X_test['posting_date'].dt.month\n",
    "X_test['year_of_postingdate'] = X_test['posting_date'].dt.year\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GyI-F853Rxa7",
   "metadata": {
    "id": "GyI-F853Rxa7"
   },
   "source": [
    "### pass the \"posting_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQHtQkrnRx_V",
   "metadata": {
    "id": "FQHtQkrnRx_V"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['posting_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GMnCaEcKReSw",
   "metadata": {
    "id": "GMnCaEcKReSw"
   },
   "source": [
    "### You need to extract day, month and year from the \"baseline_create_date\" column \n",
    "\n",
    "1.   Extract days from \"baseline_create_date\" column and store it into a new column \"day_of_createdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"baseline_create_date\" column and store it into a new column \"month_of_createdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"baseline_create_date\" column and store it into a new column \"year_of_createdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "- Note - Do as it is been shown in the previous two code boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d83d0",
   "metadata": {
    "id": "ee4d83d0"
   },
   "source": [
    "### Extracting Day, Month, Year for 'baseline_create_date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b240e1",
   "metadata": {
    "id": "32b240e1"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_createdate'] = X_train['baseline_create_date'].dt.day\n",
    "X_train['month_of_createdate'] = X_train['baseline_create_date'].dt.month\n",
    "X_train['year_of_createdate'] = X_train['baseline_create_date'].dt.year\n",
    "\n",
    "X_val['day_of_createdate'] = X_val['baseline_create_date'].dt.day\n",
    "X_val['month_of_createdate'] = X_val['baseline_create_date'].dt.month\n",
    "X_val['year_of_createdate'] = X_val['baseline_create_date'].dt.year\n",
    "\n",
    "\n",
    "X_test['day_of_createdate'] = X_test['baseline_create_date'].dt.day\n",
    "X_test['month_of_createdate'] = X_test['baseline_create_date'].dt.month\n",
    "X_test['year_of_createdate'] = X_test['baseline_create_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFgwkS5rSDDs",
   "metadata": {
    "id": "cFgwkS5rSDDs"
   },
   "source": [
    "### pass the \"baseline_create_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGYa2BEQSDg3",
   "metadata": {
    "id": "RGYa2BEQSDg3"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['baseline_create_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7a0df",
   "metadata": {
    "id": "77c7a0df"
   },
   "source": [
    "### You need to extract day, month and year from the \"due_in_date\" column \n",
    "\n",
    "1.   Extract days from \"due_in_date\" column and store it into a new column \"day_of_due\" for train, test and validation dataset \n",
    "2.   Extract months from \"due_in_date\" column and store it into a new column \"month_of_due\" for train, test and validation dataset\n",
    "3.   Extract year from \"due_in_date\" column and store it into a new column \"year_of_due\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "- Note - Do as it is been shown in the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c745547",
   "metadata": {
    "id": "5c745547"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_due'] = X_train['due_in_date'].dt.day\n",
    "X_train['month_of_due'] = X_train['due_in_date'].dt.month\n",
    "X_train['year_of_due'] = X_train['due_in_date'].dt.year\n",
    "\n",
    "X_val['day_of_due'] = X_val['due_in_date'].dt.day\n",
    "X_val['month_of_due'] = X_val['due_in_date'].dt.month\n",
    "X_val['year_of_due'] = X_val['due_in_date'].dt.year\n",
    "\n",
    "\n",
    "X_test['day_of_due'] = X_test['due_in_date'].dt.day\n",
    "X_test['month_of_due'] = X_test['due_in_date'].dt.month\n",
    "X_test['year_of_due'] = X_test['due_in_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FYLLzulGSvRd",
   "metadata": {
    "id": "FYLLzulGSvRd"
   },
   "source": [
    "pass the \"due_in_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1-s6QuY9Svrh",
   "metadata": {
    "id": "1-s6QuY9Svrh"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['due_in_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5d052",
   "metadata": {
    "id": "1ae5d052"
   },
   "source": [
    "### Check for the datatypes for train, test and validation set again\n",
    "\n",
    "- Note - all the data type should be in either int64 or float64 format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9d828",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aee9d828",
    "outputId": "e890fb7f-bef8-43eb-f57a-c38ee6d6316e"
   },
   "outputs": [],
   "source": [
    "X_train.dtypes,X_test.dtypes,X_val.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65810f55",
   "metadata": {
    "id": "65810f55"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1ad9f",
   "metadata": {
    "id": "4bb1ad9f"
   },
   "source": [
    "### Filter Method\n",
    "\n",
    "- Calling the VarianceThreshold Function \n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882509f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e882509f",
    "outputId": "3655eb8a-6cd1-440e-9638-3421ebfde92a"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)\n",
    "len(X_train.columns[constant_filter.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V9531H3jR-W2",
   "metadata": {
    "id": "V9531H3jR-W2"
   },
   "source": [
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c12e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c77c12e1",
    "outputId": "2ca0d5bc-1432-4339-a2ad-c89332612755"
   },
   "outputs": [],
   "source": [
    "constant_columns = [column for column in X_train.columns\n",
    "                    if column not in X_train.columns[constant_filter.get_support()]]\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b8610",
   "metadata": {
    "id": "6d9b8610"
   },
   "source": [
    "- transpose the feature matrice\n",
    "- print the number of duplicated features\n",
    "- select the duplicated features columns names\n",
    "\n",
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7db95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fb7db95",
    "outputId": "db3de7a3-bd82-4d52-f205-43c2a8fa82cd"
   },
   "outputs": [],
   "source": [
    "x_train_T = X_train.T\n",
    "print(x_train_T.duplicated().sum())\n",
    "duplicated_columns = x_train_T[x_train_T.duplicated()].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fa831",
   "metadata": {
    "id": "510fa831"
   },
   "source": [
    "### Filtering depending upon correlation matrix value\n",
    "- We have created a function called handling correlation which is going to return fields based on the correlation matrix value with a threshold of 0.8\n",
    "\n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67731abc",
   "metadata": {
    "id": "67731abc"
   },
   "outputs": [],
   "source": [
    "def handling_correlation(X_train,threshold=0.8):\n",
    "    corr_features = set()\n",
    "    corr_matrix = X_train.corr()\n",
    "    for i in range(len(corr_matrix .columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                corr_features.add(colname)\n",
    "    return list(corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JaE_6qVgSXl3",
   "metadata": {
    "id": "JaE_6qVgSXl3"
   },
   "source": [
    "- Note : Here we are trying to find out the relevant fields, from X_train\n",
    "- Please fill in the blanks to call handling_correlation() function with a threshold value of 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91d1a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd91d1a2",
    "outputId": "35de2893-1798-4d3e-f9a5-2e229cce4a06"
   },
   "outputs": [],
   "source": [
    "train=X_train.copy()\n",
    "handling_correlation(train.copy(),0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154da511",
   "metadata": {
    "id": "154da511"
   },
   "source": [
    "### Heatmap for X_train\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f2fe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "2e8f2fe4",
    "outputId": "eae71d28-7274-4949-e1f9-53a0506c4927"
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=20)\n",
    "sns.heatmap(X_train.merge(y_train , on = X_train.index ).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap='gist_rainbow_r', linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0d745",
   "metadata": {
    "id": "e3b0d745"
   },
   "source": [
    "#### Calling variance threshold for threshold value = 0.8\n",
    "\n",
    "- Note -  Fill in the blanks to call the appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2080f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9b2080f",
    "outputId": "2a927731-9497-480f-98af-0193914fb8e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel =VarianceThreshold(0.8)\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8c3dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cb8c3dc",
    "outputId": "ed684d1d-17ac-4146-85b2-25bc12eb783d"
   },
   "outputs": [],
   "source": [
    "sel.variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62633a84",
   "metadata": {
    "id": "62633a84"
   },
   "source": [
    "### Features columns are \n",
    "- 'year_of_createdate' \n",
    "- 'year_of_due'\n",
    "- 'day_of_createdate'\n",
    "- 'year_of_postingdate'\n",
    "- 'month_of_due'\n",
    "- 'month_of_createdate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f1ad0",
   "metadata": {
    "id": "651f1ad0"
   },
   "source": [
    "# Modelling \n",
    "\n",
    "#### Now you need to compare with different machine learning models, and needs to find out the best predicted model\n",
    "\n",
    "- Linear Regression\n",
    "- Decision Tree Regression\n",
    "- Random Forest Regression\n",
    "- Support Vector Regression\n",
    "- Extreme Gradient Boost Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PicEhSuUUOkt",
   "metadata": {
    "id": "PicEhSuUUOkt"
   },
   "source": [
    "### You need to make different blank list for different evaluation matrix \n",
    "\n",
    "- MSE\n",
    "- R2\n",
    "- Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e12b0",
   "metadata": {
    "id": "701e12b0"
   },
   "outputs": [],
   "source": [
    "MSE_Score = []\n",
    "R2_Score = []\n",
    "Algorithm = []\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29310119",
   "metadata": {
    "id": "29310119"
   },
   "source": [
    "### You need to start with the baseline model Linear Regression\n",
    "\n",
    "- Step 1 : Call the Linear Regression from sklearn library\n",
    "- Step 2 : make an object of Linear Regression \n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdea395",
   "metadata": {
    "id": "6bdea395"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Algorithm.append('LinearRegression')\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G02cpnBhXJ14",
   "metadata": {
    "id": "G02cpnBhXJ14"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69ca19",
   "metadata": {
    "id": "0f69ca19"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CsmScbHjYMv1",
   "metadata": {
    "id": "CsmScbHjYMv1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe653295",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe653295",
    "outputId": "2d36a9f5-233e-4658-9bcf-fc7d2b33144f"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LokxV2LGYUVh",
   "metadata": {
    "id": "LokxV2LGYUVh"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c405bd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c405bd3",
    "outputId": "6d52f0dc-90e5-4ffe-e0e7-ed17ab5d9cf7"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e65c86",
   "metadata": {
    "id": "b0e65c86"
   },
   "source": [
    "### You need to start with the baseline model Support Vector Regression\n",
    "\n",
    "- Step 1 : Call the Support Vector Regressor from sklearn library\n",
    "- Step 2 : make an object of SVR\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5de08",
   "metadata": {
    "id": "ccb5de08"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "Algorithm.append('SVR')\n",
    "regressor = SVR()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zz9kcrViYt7e",
   "metadata": {
    "id": "zz9kcrViYt7e"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for \"y_test\" and \"predicted\" dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9db76",
   "metadata": {
    "id": "5bb9db76"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0YAxd8N9Y0hJ",
   "metadata": {
    "id": "0YAxd8N9Y0hJ"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee71b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6ee71b1",
    "outputId": "01b005a9-8239-4cd0-ae36-88215639dbbf"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eGcqS5EcY4BI",
   "metadata": {
    "id": "eGcqS5EcY4BI"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72c1ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa72c1ec",
    "outputId": "0b4a641f-a947-4f82-da49-ee12ffc73710"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad18bb3",
   "metadata": {
    "id": "dad18bb3"
   },
   "source": [
    "### Your next model would be Decision Tree Regression\n",
    "\n",
    "- Step 1 : Call the Decision Tree Regressor from sklearn library\n",
    "- Step 2 : make an object of Decision Tree\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a51eb",
   "metadata": {
    "id": "1b6a51eb"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Algorithm.append('DecisionTreeRegressor')\n",
    "regressor = DecisionTreeRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AOzfgfeOZo3F",
   "metadata": {
    "id": "AOzfgfeOZo3F"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e6983",
   "metadata": {
    "id": "776e6983"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eI6d49DQZrhW",
   "metadata": {
    "id": "eI6d49DQZrhW"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fb55c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "155fb55c",
    "outputId": "3facbc21-9a1d-44c0-ec98-502afce991ab"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbGXvBLQZw5E",
   "metadata": {
    "id": "sbGXvBLQZw5E"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74d515",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d74d515",
    "outputId": "f9975b9e-f8ec-49ea-b4f9-7054d2b55ddb"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9979b",
   "metadata": {
    "id": "4ae9979b"
   },
   "source": [
    "### Your next model would be Random Forest Regression\n",
    "\n",
    "- Step 1 : Call the Random Forest Regressor from sklearn library\n",
    "- Step 2 : make an object of Random Forest\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e476a",
   "metadata": {
    "id": "a69e476a"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "Algorithm.append('RandomForestRegressor')\n",
    "regressor = RandomForestRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XNcEJF-6anof",
   "metadata": {
    "id": "XNcEJF-6anof"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f63f4",
   "metadata": {
    "id": "826f63f4"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yMbyr9V4ati1",
   "metadata": {
    "id": "yMbyr9V4ati1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9fb54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55b9fb54",
    "outputId": "42e00d4b-a238-4801-8a15-6ea6ea82e4de"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiBawcCsaw_Z",
   "metadata": {
    "id": "tiBawcCsaw_Z"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277c13e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8277c13e",
    "outputId": "7678c1b3-8b70-4219-c00f-5498bb73b652"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b21881",
   "metadata": {
    "id": "e6b21881"
   },
   "source": [
    "### The last but not the least model would be XGBoost or Extreme Gradient Boost Regression\n",
    "\n",
    "- Step 1 : Call the XGBoost Regressor from xgb library\n",
    "- Step 2 : make an object of Xgboost\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose### Extreme Gradient Boost Regression\n",
    "- Note -  No need to change the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a38ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "705a38ec",
    "outputId": "cd850a54-8b77-4c6b-b5b2-710809a1437f"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "Algorithm.append('XGB Regressor')\n",
    "regressor = xgb.XGBRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ierNZkb9bQDD",
   "metadata": {
    "id": "ierNZkb9bQDD"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a9d2f",
   "metadata": {
    "id": "507a9d2f"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84UZ2ojsbWaH",
   "metadata": {
    "id": "84UZ2ojsbWaH"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ac250",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e78ac250",
    "outputId": "5de25be3-26b8-424b-d43c-649ecd852472"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9FJFyaVbbbAH",
   "metadata": {
    "id": "9FJFyaVbbbAH"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765ba35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f765ba35",
    "outputId": "b29a29a7-556e-41ef-ba1b-9bab2a2f94c4"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71bc90f",
   "metadata": {
    "id": "a71bc90f"
   },
   "source": [
    "## You need to make the comparison list into a comparison dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5159a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ff5159a7",
    "outputId": "d267d38d-1fe2-4163-d5a8-a912062d4294"
   },
   "outputs": [],
   "source": [
    "comparison_dataframe=pd.DataFrame(zip(Algorithm,MSE_Score,R2_Score),columns=['Algorithm','MSE_Score','R2_Score'])\n",
    "comparison_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e61c60",
   "metadata": {
    "id": "62e61c60"
   },
   "source": [
    "## Now from the Comparison table, you need to choose the best fit model\n",
    "\n",
    "- Step 1 - Fit X_train and y_train inside the model \n",
    "- Step 2 - Predict the X_test dataset\n",
    "- Step 3 - Predict the X_val dataset\n",
    "\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07c258",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e07c258",
    "outputId": "6d22437a-6923-42e6-a372-e964f5c0a22c"
   },
   "outputs": [],
   "source": [
    "regressorfinal = xgb.XGBRegressor()\n",
    "regressorfinal.fit(X_train, y_train)\n",
    "predictedfinal = regressorfinal.predict(X_test)\n",
    "predict_testfinal = regressorfinal.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4df6c4",
   "metadata": {
    "id": "8e4df6c4"
   },
   "source": [
    "### Calculate the Mean Square Error for test dataset\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb466d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fb466d0",
    "outputId": "cc73bf2d-8fd7-4e8f-a711-2e49ab27e8ca"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,predictedfinal,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27f87f",
   "metadata": {
    "id": "ce27f87f"
   },
   "source": [
    "### Calculate the mean Square Error for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47978ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b47978ea",
    "outputId": "2cce6739-26a3-4c25-9012-6adf21f98274"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_val,predict_testfinal,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30014dbd",
   "metadata": {
    "id": "30014dbd"
   },
   "source": [
    "### Calculate the R2 score for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a162737",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a162737",
    "outputId": "b061b2ff-895f-4dd6-f225-e4b9324291fe"
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, predictedfinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9853b0",
   "metadata": {
    "id": "1c9853b0"
   },
   "source": [
    "### Calculate the R2 score for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6dc77c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a6dc77c",
    "outputId": "02f3c7d7-af64-481b-8943-5a84b4a8efb7"
   },
   "outputs": [],
   "source": [
    "r2_score(y_val, predict_testfinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499522d9",
   "metadata": {
    "id": "499522d9"
   },
   "source": [
    "### Calculate the Accuracy for train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f1ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a4f1ce8",
    "outputId": "c44d3cb3-2845-4f44-f009-7da84e0e4d40"
   },
   "outputs": [],
   "source": [
    "acurr1=round(regressorfinal.score(X_train,y_train)*100,2)\n",
    "print(round(acurr1,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1c921",
   "metadata": {
    "id": "12a1c921"
   },
   "source": [
    "### Calculate the accuracy for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2579b4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2579b4f",
    "outputId": "7fd1d049-6d2c-479a-bcc0-d1daf906e8da"
   },
   "outputs": [],
   "source": [
    "acurr2=round(regressorfinal.score(X_val,y_val)*100,2)\n",
    "print(round(acurr2,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b82e84",
   "metadata": {
    "id": "79b82e84"
   },
   "source": [
    "### Calculate the accuracy for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e6431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f09e6431",
    "outputId": "6bd14170-ee31-453c-e15d-51d72878024d"
   },
   "outputs": [],
   "source": [
    "acurr3=round(regressorfinal.score(X_test,y_test)*100,2)\n",
    "print(round(acurr3,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488a5d9",
   "metadata": {
    "id": "9488a5d9"
   },
   "source": [
    "## Specify the reason behind choosing your machine learning model \n",
    "\n",
    "- Note : Provide your answer as a text here\n",
    "-**Ans** : \n",
    "\n",
    ">I have selected XGB Regressor as my final model for this dataset.\n",
    ">*   Because the R2 score and MSE of XGB Regressor is ideal.\n",
    ">*   It gives acuracy  by learning from errors made by prior methods.\n",
    ">*   Morever it is best in terms of acuracy and speed.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a6519",
   "metadata": {
    "id": "387a6519"
   },
   "source": [
    "## Now you need to pass the Nulldata dataframe into this machine learning model\n",
    "\n",
    "#### In order to pass this Nulldata dataframe into the ML model, we need to perform the following\n",
    "\n",
    "- Step 1 : Label Encoding \n",
    "- Step 2 : Day, Month and Year extraction \n",
    "- Step 3 : Change all the column data type into int64 or float64\n",
    "- Step 4 : Need to drop the useless columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I7JuxAkdiAdI",
   "metadata": {
    "id": "I7JuxAkdiAdI"
   },
   "source": [
    "### Display the Nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a51d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "6d6a51d2",
    "outputId": "df60bcee-ebf6-4a92-a8d8-8c5b1b9bcacf"
   },
   "outputs": [],
   "source": [
    "nulldata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vamx5xqtiHCH",
   "metadata": {
    "id": "Vamx5xqtiHCH"
   },
   "source": [
    "### Check for the number of rows and columns in the nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de1092",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59de1092",
    "outputId": "b6b69172-20f7-4eff-dff7-f451971e9ef9"
   },
   "outputs": [],
   "source": [
    "nulldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BxzHNbBjpqXL",
   "metadata": {
    "id": "BxzHNbBjpqXL"
   },
   "source": [
    "### Check the Description and Information of the nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294d29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6294d29",
    "outputId": "57af439a-0e52-4f8a-d5c6-f9e6996c8415"
   },
   "outputs": [],
   "source": [
    "print(nulldata.describe())\n",
    "print(nulldata.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe860d94",
   "metadata": {
    "id": "fe860d94"
   },
   "source": [
    "### Storing the Nulldata into a different dataset \n",
    "# for BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16352034",
   "metadata": {
    "id": "16352034"
   },
   "outputs": [],
   "source": [
    "nulldata1=nulldata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f35b8c",
   "metadata": {
    "id": "00f35b8c"
   },
   "source": [
    "### Call the Label Encoder for Nulldata\n",
    "\n",
    "- Note - you are expected to fit \"business_code\" as it is a categorical variable\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf04b17",
   "metadata": {
    "id": "baf04b17"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "business_codern = LabelEncoder()\n",
    "business_codern.fit(nulldata['business_code'])\n",
    "nulldata['business_code_enc'] = business_codern.transform(nulldata['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZCPBK9karIR-",
   "metadata": {
    "id": "ZCPBK9karIR-"
   },
   "source": [
    "### Now you need to manually replacing str values with numbers\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64924be",
   "metadata": {
    "id": "c64924be"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_number'] = nulldata['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55f5f6",
   "metadata": {
    "id": "9a55f5f6"
   },
   "source": [
    "## You need to extract day, month and year from the \"clear_date\", \"posting_date\", \"due_in_date\", \"baseline_create_date\" columns\n",
    "\n",
    "\n",
    "##### 1.   Extract day from \"clear_date\" column and store it into 'day_of_cleardate'\n",
    "##### 2.   Extract month from \"clear_date\" column and store it into 'month_of_cleardate'\n",
    "##### 3.   Extract year from \"clear_date\" column and store it into 'year_of_cleardate'\n",
    "\n",
    "\n",
    "\n",
    "##### 4.   Extract day from \"posting_date\" column and store it into 'day_of_postingdate'\n",
    "##### 5.   Extract month from \"posting_date\" column and store it into 'month_of_postingdate'\n",
    "##### 6.   Extract year from \"posting_date\" column and store it into 'year_of_postingdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 7.   Extract day from \"due_in_date\" column and store it into 'day_of_due'\n",
    "##### 8.   Extract month from \"due_in_date\" column and store it into 'month_of_due'\n",
    "##### 9.   Extract year from \"due_in_date\" column and store it into 'year_of_due'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 10.   Extract day from \"baseline_create_date\" column and store it into 'day_of_createdate'\n",
    "##### 11.   Extract month from \"baseline_create_date\" column and store it into 'month_of_createdate'\n",
    "##### 12.   Extract year from \"baseline_create_date\" column and store it into 'year_of_createdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed To use - \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166fbe4",
   "metadata": {
    "id": "4166fbe4"
   },
   "outputs": [],
   "source": [
    "nulldata['day_of_cleardate'] = nulldata['clear_date'].dt.day\n",
    "nulldata['month_of_cleardate'] = nulldata['clear_date'].dt.month\n",
    "nulldata['year_of_cleardate'] = nulldata['clear_date'].dt.year\n",
    "\n",
    "nulldata['day_of_postingdate'] = nulldata['posting_date'].dt.day\n",
    "nulldata['month_of_postingdate'] = nulldata['posting_date'].dt.month\n",
    "nulldata['year_of_postingdate'] = nulldata['posting_date'].dt.year\n",
    "\n",
    "nulldata['day_of_due'] = nulldata['due_in_date'].dt.day\n",
    "nulldata['month_of_due'] = nulldata['due_in_date'].dt.month\n",
    "nulldata['year_of_due'] = nulldata['due_in_date'].dt.year\n",
    "\n",
    "nulldata['day_of_createdate'] = nulldata['baseline_create_date'].dt.day\n",
    "nulldata['month_of_createdate'] = nulldata['baseline_create_date'].dt.month\n",
    "nulldata['year_of_createdate'] = nulldata['baseline_create_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QeHWJYrAvOC6",
   "metadata": {
    "id": "QeHWJYrAvOC6"
   },
   "source": [
    "### Use Label Encoder1 of all the following columns - \n",
    "- 'cust_payment_terms' and store into 'cust_payment_terms_enc'\n",
    "- 'business_code' and store into 'business_code_enc'\n",
    "- 'name_customer' and store into 'name_customer_enc'\n",
    "\n",
    "Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac330e2",
   "metadata": {
    "id": "bac330e2"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_payment_terms_enc']=label_encoder1.transform(nulldata['cust_payment_terms'])\n",
    "nulldata['business_code_enc']=label_encoder1.transform(nulldata['business_code'])\n",
    "nulldata['name_customer_enc']=label_encoder.transform(nulldata['name_customer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zD9I-XqQwC28",
   "metadata": {
    "id": "zD9I-XqQwC28"
   },
   "source": [
    "### Check for the datatypes of all the columns of Nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f72517",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4f72517",
    "outputId": "436f63ed-5c77-431e-aca1-008e719f7353"
   },
   "outputs": [],
   "source": [
    "nulldata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd5452",
   "metadata": {
    "id": "17cd5452"
   },
   "source": [
    "### Now you need to drop all the unnecessary columns - \n",
    "\n",
    "- 'business_code'\n",
    "- \"baseline_create_date\"\n",
    "- \"due_in_date\"\n",
    "- \"posting_date\"\n",
    "- \"name_customer\"\n",
    "- \"clear_date\"\n",
    "- \"cust_payment_terms\"\n",
    "- 'day_of_cleardate'\n",
    "- \"month_of_cleardate\"\n",
    "- \"year_of_cleardate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c82076",
   "metadata": {
    "id": "d7c82076"
   },
   "outputs": [],
   "source": [
    "nulldata.drop(columns=['business_code','baseline_create_date','due_in_date','posting_date','name_customer','clear_date','cust_payment_terms',\n",
    "                       'day_of_cleardate','month_of_cleardate','year_of_cleardate'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q_NCr9IPweVq",
   "metadata": {
    "id": "Q_NCr9IPweVq"
   },
   "source": [
    "### Check the information of the \"nulldata\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ffee0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e7ffee0",
    "outputId": "f6d18bb9-a9c6-4618-d285-0330db65b109"
   },
   "outputs": [],
   "source": [
    "nulldata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-XvjhWqmwi-C",
   "metadata": {
    "id": "-XvjhWqmwi-C"
   },
   "source": [
    "### Compare \"nulldata\" with the \"X_test\" dataframe \n",
    "\n",
    "- use info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4b62d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02f4b62d",
    "outputId": "049c15f2-5ee8-47b7-d9ba-f86db6f85c74"
   },
   "outputs": [],
   "source": [
    "print(nulldata.info(),X_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Us3ey-9zwqjq",
   "metadata": {
    "id": "Us3ey-9zwqjq"
   },
   "source": [
    "### You must have noticed that there is a mismatch in the column sequence while compairing the dataframes\n",
    "\n",
    "- Note - In order to fed into the machine learning model, you need to edit the sequence of \"nulldata\", similar to the \"X_test\" dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vduVNt1kxPW-",
   "metadata": {
    "id": "vduVNt1kxPW-"
   },
   "source": [
    "- Display all the columns of the X_test dataframe \n",
    "- Display all the columns of the Nulldata dataframe \n",
    "- Store the Nulldata with new sequence into a new dataframe \n",
    "\n",
    "\n",
    "- Note - The code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729353e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6729353e",
    "outputId": "166137a2-4111-4f59-9e31-cd75c28e7e6b"
   },
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd9c5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47bd9c5e",
    "outputId": "389c30ea-f0c5-4924-ed97-3e345adb9ff9"
   },
   "outputs": [],
   "source": [
    "nulldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a2103",
   "metadata": {
    "id": "aa5a2103"
   },
   "outputs": [],
   "source": [
    "nulldata2=nulldata[['cust_number', 'buisness_year', 'doc_id', 'converted_usd',\n",
    "       'business_code_enc', 'name_customer_enc', 'cust_payment_terms_enc',\n",
    "       'day_of_postingdate', 'month_of_postingdate', 'year_of_postingdate',\n",
    "       'day_of_createdate', 'month_of_createdate', 'year_of_createdate',\n",
    "       'day_of_due', 'month_of_due', 'year_of_due']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8b021",
   "metadata": {
    "id": "1dc8b021"
   },
   "source": [
    "### Display the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39785a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "2f39785a",
    "outputId": "e5b831f7-1583-49af-ee5e-a7095096cd73"
   },
   "outputs": [],
   "source": [
    "nulldata2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b88c5a",
   "metadata": {
    "id": "27b88c5a"
   },
   "source": [
    "### Now you can pass this dataset into you final model and store it into \"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b6388",
   "metadata": {
    "id": "9e0b6388"
   },
   "outputs": [],
   "source": [
    "final_result = regressorfinal.predict(nulldata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653d3c6",
   "metadata": {
    "id": "9653d3c6"
   },
   "source": [
    "### you need to make the final_result as dataframe, with a column name \"avg_delay\"\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef814d",
   "metadata": {
    "id": "25ef814d"
   },
   "outputs": [],
   "source": [
    "final_result = pd.Series(final_result,name='avg_delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C86staIhyf2C",
   "metadata": {
    "id": "C86staIhyf2C"
   },
   "source": [
    "### Display the \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd46406",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fd46406",
    "outputId": "b76ab10d-662a-4fe7-8b19-3c553199071f"
   },
   "outputs": [],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f71a7e",
   "metadata": {
    "id": "44f71a7e"
   },
   "source": [
    "### Now you need to merge this final_result dataframe with the BACKUP of \"nulldata\" Dataframe which we have created in earlier steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0969d",
   "metadata": {
    "id": "e8f0969d"
   },
   "outputs": [],
   "source": [
    "nulldata1.reset_index(drop=True,inplace=True)\n",
    "Final = nulldata1.merge(final_result , on = nulldata.index )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G-hLtxXgy4GZ",
   "metadata": {
    "id": "G-hLtxXgy4GZ"
   },
   "source": [
    "### Display the \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb4dc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "71fb4dc0",
    "outputId": "b0ec3fe6-311d-4735-acfe-2b47e96670ae"
   },
   "outputs": [],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4sc27Uz-y-0O",
   "metadata": {
    "id": "4sc27Uz-y-0O"
   },
   "source": [
    "### Check for the Number of Rows and Columns in your \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5iUXOIhzy_HR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iUXOIhzy_HR",
    "outputId": "c3a726c6-6209-4d3a-b446-35b986e4a6cb"
   },
   "outputs": [],
   "source": [
    "Final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48886d2c",
   "metadata": {
    "id": "48886d2c"
   },
   "source": [
    "### Now, you need to do convert the below fields back into date and time format \n",
    "\n",
    "- Convert \"due_in_date\" into datetime format\n",
    "- Convert \"avg_delay\" into datetime format\n",
    "- Create a new column \"clear_date\" and store the sum of \"due_in_date\" and \"avg_delay\"\n",
    "- display the new \"clear_date\" column\n",
    "- Note - Code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243abc2d",
   "metadata": {
    "id": "243abc2d"
   },
   "outputs": [],
   "source": [
    "Final['clear_date'] = pd.to_datetime(Final['due_in_date']) + pd.to_timedelta(Final['avg_delay'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9QcX_fAjIkYR",
   "metadata": {
    "id": "9QcX_fAjIkYR"
   },
   "source": [
    "### Display the \"clear_date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e1486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "740e1486",
    "outputId": "d66e4300-09ab-479f-d0d3-6a4a1874abc8"
   },
   "outputs": [],
   "source": [
    "Final['clear_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MSkNLq6-z7rZ",
   "metadata": {
    "id": "MSkNLq6-z7rZ"
   },
   "source": [
    "### Convert the average delay into number of days format \n",
    "\n",
    "- Note - Formula = avg_delay//(24 * 3600)\n",
    "- Note - full code is given for this, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b618a",
   "metadata": {
    "id": "ce6b618a"
   },
   "outputs": [],
   "source": [
    "Final['avg_delay'] = Final.apply(lambda row: row.avg_delay//(24 * 3600), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wbBBZPjP0W7o",
   "metadata": {
    "id": "wbBBZPjP0W7o"
   },
   "source": [
    "### Display the \"avg_delay\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494982f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a494982f",
    "outputId": "b5f8a2f1-3b9f-43b3-9d09-d4bd1cf26782",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final['avg_delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d8811",
   "metadata": {
    "id": "815d8811"
   },
   "source": [
    "### Now you need to convert average delay column into bucket\n",
    "\n",
    "- Need to perform binning \n",
    "- create a list of bins i.e. bins= [0,15,30,45,60,100]\n",
    "- create a list of labels i.e. labels = ['0-15','16-30','31-45','46-60','Greatar than 60']\n",
    "- perform binning by using cut() function from \"Final\" dataframe\n",
    "\n",
    "\n",
    "- Please fill up the first two rows of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797e4b5",
   "metadata": {
    "id": "c797e4b5"
   },
   "outputs": [],
   "source": [
    "bins= [-100,0,15,30,45,60,100]\n",
    "labels = ['Before Due Date','0-15','16-30','31-45','46-60','Greatar than 60']\n",
    "Final['Aging Bucket'] = pd.cut(Final['avg_delay'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35725f",
   "metadata": {
    "id": "1c35725f"
   },
   "source": [
    "### Now you need to drop \"key_0\" and \"avg_delay\" columns from the \"Final\" Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bc6a3",
   "metadata": {
    "id": "b31bc6a3"
   },
   "outputs": [],
   "source": [
    "Final.drop(columns=['key_0','avg_delay'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ui-tyIvU0-5u",
   "metadata": {
    "id": "Ui-tyIvU0-5u"
   },
   "source": [
    "### Display the count of each categoty of new \"Aging Bucket\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e16218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6e16218",
    "outputId": "012f7e2f-e611-4da9-9cd9-f8b6e2fbfa74"
   },
   "outputs": [],
   "source": [
    "Final['Aging Bucket'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kgYegy551GKJ",
   "metadata": {
    "id": "kgYegy551GKJ"
   },
   "source": [
    "### Display your final dataset with aging buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc87ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "c4bc87ec",
    "outputId": "fbdbb449-b325-4d9e-c353-2e83c7a8f8e7"
   },
   "outputs": [],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ji7AoDCB1L_x",
   "metadata": {
    "id": "Ji7AoDCB1L_x"
   },
   "source": [
    "### Store this dataframe into the .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d0b8d",
   "metadata": {
    "id": "727d0b8d"
   },
   "outputs": [],
   "source": [
    "Final.to_csv('model.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FK0fabl61SkC",
   "metadata": {
    "id": "FK0fabl61SkC"
   },
   "source": [
    "# END OF THE PROJECT"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HRC70078W_KUNAL_KUMAR_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
